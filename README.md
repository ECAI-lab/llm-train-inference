# llm-train-inference

Some resources for training and inferencing on LLMs.

GPU memory requirement: https://rahulschand.github.io/gpu_poor/